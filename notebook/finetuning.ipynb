{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724bf6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from colorama import Fore, Style\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "from colorama import init, Fore, Style\n",
    "init(autoreset=True)\n",
    "\n",
    "print(Fore.GREEN + \"All libraries imported successfully!\" + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2e70aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  base_model: meta-llama/Llama-3.2-1B\n",
      "  dataset_path: ../data/synthetic_QA_pairs/synthetic_output_assessment_results.json\n",
      "  output_dir: ../checkpoints/bloombergTerminal-lora-llama3-1b\n"
     ]
    }
   ],
   "source": [
    "TRAINING_CONFIG = {\n",
    "    \"base_model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"dataset_path\": \"../data/synthetic_QA_pairs/synthetic_output_assessment_results.json\",\n",
    "    \"output_dir\": \"../checkpoints/bloombergTerminal-lora-llama3-1b\",\n",
    "}\n",
    "\n",
    "print(Fore.CYAN + \"Training Configuration:\" + Style.RESET_ALL)\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c89b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: ../data/synthetic_QA_pairs/synthetic_output_assessment_results.json\n",
      "Dataset Preview:\n",
      "Dataset columns: ['question', 'answer', 'quality']\n",
      "Number of samples in dataset: 3082\n",
      "\n",
      "üîç Sample from dataset:\n",
      "  question: What is a Credit Default Swap (CDS) and why is its valuation complex?\n",
      "  answer: A Credit Default Swap (CDS) is a financial instrument designed to hedge against credit risk, and the...\n",
      "  quality: {'accuracy': {'explanation': 'The answer is mostly accurate but could be more precise or detailed. T...\n"
     ]
    }
   ],
   "source": [
    "print(Fore.YELLOW + f\"Loading dataset from: {TRAINING_CONFIG['dataset_path']}\" + Style.RESET_ALL)\n",
    "\n",
    "dataset = load_dataset('json', data_files=TRAINING_CONFIG['dataset_path'], split='train')\n",
    "\n",
    "##Preview dataset\n",
    "print(Fore.MAGENTA + \"Dataset Preview:\" + Style.RESET_ALL)\n",
    "#dataset columns\n",
    "print(f\"Dataset columns: {dataset.column_names}\")\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "print(Fore.CYAN + \"\\nüîç Sample from dataset:\" + Style.RESET_ALL)\n",
    "sample = dataset[0]\n",
    "for key, value in sample.items():\n",
    "    print(f\"  {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c4aaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Tokenizer\u001b[39;00m\n\u001b[32m      2\u001b[39m hf_token = \u001b[33m\"\u001b[39m\u001b[33mhf_xxxx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m hf_token = \u001b[43mos\u001b[49m.getenv(\u001b[33m\"\u001b[39m\u001b[33mHF_TOKEN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m      7\u001b[39m     TRAINING_CONFIG[\u001b[33m'\u001b[39m\u001b[33mbase_model\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m      8\u001b[39m     token=hf_token, \n\u001b[32m      9\u001b[39m     trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "## Tokenizer\n",
    "hf_token = \"ADD_YOUR_HUGGINGFACE_TOKEN_HERE\"  # Replace with your actual token or set to None if not needed\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    TRAINING_CONFIG['base_model'], \n",
    "    token=hf_token, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(Fore.GREEN + \"‚úÖ Tokenizer loaded and configured!\" + Style.RESET_ALL)\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"Padding token: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})\")\n",
    "print(f\"EOS token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})\")\n",
    "\n",
    "# Test tokenization\n",
    "test_text = \"Hello, how are you?\"\n",
    "tokens = tokenizer.tokenize(test_text)\n",
    "print(f\"Test tokenization of '{test_text}':\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {tokenizer.convert_tokens_to_ids(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc27c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Chat template example:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant specializing in the Bloomberg Terminal. Provide clear, accurate answers to questions about its functions and usage.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is a Credit Default Swap (CDS) and why is its valuation complex?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A Credit Default Swap (CDS) is a financial instrument designed to hedge against credit risk, and the valuation of CDS is complex due to various factors including default probability, loss amount, recovery rate, and timing of default.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "def format_chat_template(batch, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts question-answer pairs into proper chat format for instruction following\n",
    "    \"\"\"\n",
    "    system_prompt = \"You are a helpful assistant specializing in the Bloomberg Terminal. Provide clear, accurate answers to questions about its functions and usage.\"\n",
    "    \n",
    "    questions = batch[\"question\"]\n",
    "    answers = batch[\"answer\"]\n",
    "    \n",
    "    texts = []\n",
    "    for question, answer in zip(questions, answers):\n",
    "        # Create the conversation structure\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "        \n",
    "        # Check if tokenizer has a chat template\n",
    "        if tokenizer.chat_template is not None:\n",
    "            # Use the tokenizer's built-in chat template\n",
    "            formatted_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        else:\n",
    "            # Manually format using Llama-3 style template\n",
    "            formatted_text = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_prompt}<|eot_id|>\"\n",
    "            formatted_text += f\"<|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|>\"\n",
    "            formatted_text += f\"<|start_header_id|>assistant<|end_header_id|>\\n\\n{answer}<|eot_id|>\"\n",
    "        \n",
    "        texts.append(formatted_text)\n",
    "        \n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Test the function with one example\n",
    "test_batch = {\n",
    "    \"question\": [dataset[0][\"question\"]], \n",
    "    \"answer\": [dataset[0][\"answer\"]]\n",
    "}\n",
    "test_result = format_chat_template(test_batch, tokenizer)\n",
    "print(\"üìù Chat template example:\")\n",
    "print(test_result[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a Credit Default Swap (CDS) and why is its valuation complex?',\n",
       " 'answer': 'A Credit Default Swap (CDS) is a financial instrument designed to hedge against credit risk, and the valuation of CDS is complex due to various factors including default probability, loss amount, recovery rate, and timing of default.',\n",
       " 'quality': {'accuracy': {'explanation': 'The answer is mostly accurate but could be more precise or detailed. The key factors affecting CDS valuation are correctly mentioned, but the explanation lacks depth and does not provide a clear example or scenario to illustrate its complexity.',\n",
       "   'score': 9},\n",
       "  'style': {'explanation': 'The style is excellent, professional, and perfectly clear. The answer provides a concise yet accurate description of CDS valuation complexity, making it easy for readers to understand the topic.',\n",
       "   'score': 10}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62fdf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying chat template to entire dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting dataset with chat template: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3082/3082 [00:00<00:00, 167591.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of examples: 3082\n",
      "   New features: {'question': Value('string'), 'answer': Value('string'), 'quality': {'accuracy': {'explanation': Value('string'), 'score': Value('int64')}, 'style': {'explanation': Value('string'), 'score': Value('int64')}}, 'text': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying chat template to entire dataset...\")\n",
    "train_dataset = dataset.map(\n",
    "    lambda batch: format_chat_template(batch, tokenizer), \n",
    "    batched=True, \n",
    "    desc=\"Formatting dataset with chat template\"\n",
    ")\n",
    "\n",
    "print(f\"   Number of examples: {len(train_dataset)}\")\n",
    "print(f\"   New features: {train_dataset.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d78817ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average length: 525 characters\n",
      "   Min length: 365 characters\n",
      "   Max length: 866 characters\n"
     ]
    }
   ],
   "source": [
    "text_lengths = [len(text) for text in train_dataset[\"text\"]]\n",
    "print(f\"   Average length: {sum(text_lengths)/len(text_lengths):.0f} characters\")\n",
    "print(f\"   Min length: {min(text_lengths)} characters\")\n",
    "print(f\"   Max length: {max(text_lengths)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88bc16a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of formatted training text:\n",
      "==================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant specializing in the Bloomberg Terminal. Provide clear, accurate answers to questions about its functions and usage.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is a Credit Default Swap (CDS) and why is its valuation complex?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A Credit Default Swap (CDS) is a financial instrument designed to hedge against credit risk, and the valuation of CDS is complex due to various factors including default probability, loss amount, recovery rate, and timing of default.<|eot_id|>\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nExample of formatted training text:\")\n",
    "print(\"=\"*50)\n",
    "print(train_dataset[0]['text'])\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dcb0632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4-bit loading: True\n",
      "   Double quantization: True\n",
      "   Quantization type: nf4\n",
      "   Compute dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "## Configure 4 bit quantization\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_type=torch.float16\n",
    ")\n",
    "\n",
    "print(f\"   4-bit loading: {quant_config.load_in_4bit}\")\n",
    "print(f\"   Double quantization: {quant_config.bnb_4bit_use_double_quant}\")\n",
    "print(f\"   Quantization type: {quant_config.bnb_4bit_quant_type}\")\n",
    "print(f\"   Compute dtype: {quant_config.bnb_4bit_compute_dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8e4ef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 8-bit optimizer is not available on your device, only available on CUDA for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model type: LlamaForCausalLM\n",
      "   Device map: {'': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "## Load the base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    TRAINING_CONFIG['base_model'],\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quant_config,\n",
    "    token=hf_token,\n",
    "    cache_dir=\"./model_cache\",\n",
    ")\n",
    "\n",
    "print(f\"   Model type: {type(model).__name__}\")\n",
    "print(f\"   Device map: {model.hf_device_map if hasattr(model, 'hf_device_map') else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0346ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total parameters: 749,275,136\n",
      "   Trainable parameters: 262,735,872\n"
     ]
    }
   ],
   "source": [
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "117ee8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preparation:\n",
      "Trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "## Enable Gradient Checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "## Enable kbit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Check what changed\n",
    "trainable_params_after = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"After preparation:\")\n",
    "print(f\"Trainable parameters: {trainable_params_after:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe36922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora-finetuning-bloombergterminal (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
